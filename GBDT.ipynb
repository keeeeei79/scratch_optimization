{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4d0d74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f94f4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e8e4b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5c3a7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y = load_diabetes(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8f2958d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50aa97",
   "metadata": {},
   "source": [
    "# まず連続値の予測\n",
    "- 糖尿病患者の検査数値と1年後の進行状況のデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "63302b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'y'\n",
    "features = [c for c in df.columns if c != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "80645f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "train, valid = train_test_split(train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fa3ec7e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x142e3d220>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(data=train[features], label=train[target], free_raw_data=False)\n",
    "dtrain.construct()\n",
    "dvalid = lgb.Dataset(data=valid[features], label=valid[target], free_raw_data=False)\n",
    "dvalid.construct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e81289ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,\n",
    "    'metric': 'root_mean_squared_error',\n",
    "    'nthread': -1,\n",
    "    'num_leaves': 7,\n",
    "    'seed': 57,\n",
    "    'verbose': -1,\n",
    "    \n",
    "#     'colsample_bytree': 0.05,\n",
    "#     'min_child_weight': 10,\n",
    "#     'min_split_gain': 0.1,\n",
    "#     'reg_alpha': 10,\n",
    "#     'reg_lambda': 1,\n",
    "#     'subsample': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1214393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = lgb.Booster(params=params, train_set=dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1f7e78e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.train_set.init_score is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2d24c37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x142e3db80>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain._reverse_update_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "89c60c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.init_score is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874858d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec387f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 73.4856\tvalid_1's rmse: 78.4953\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 70.0847\tvalid_1's rmse: 75.6773\n",
      "[3]\ttraining's rmse: 66.7682\tvalid_1's rmse: 72.4375\n",
      "[4]\ttraining's rmse: 64.0703\tvalid_1's rmse: 70.2267\n",
      "[5]\ttraining's rmse: 61.5833\tvalid_1's rmse: 68.49\n",
      "[6]\ttraining's rmse: 59.4559\tvalid_1's rmse: 66.4946\n",
      "[7]\ttraining's rmse: 57.7101\tvalid_1's rmse: 65.2463\n",
      "[8]\ttraining's rmse: 56.0731\tvalid_1's rmse: 64.1842\n",
      "[9]\ttraining's rmse: 54.6497\tvalid_1's rmse: 62.9557\n",
      "[10]\ttraining's rmse: 53.2851\tvalid_1's rmse: 62.1439\n",
      "[11]\ttraining's rmse: 52.0745\tvalid_1's rmse: 61.7006\n",
      "[12]\ttraining's rmse: 51.0258\tvalid_1's rmse: 61.6334\n",
      "[13]\ttraining's rmse: 50.1159\tvalid_1's rmse: 61.426\n",
      "[14]\ttraining's rmse: 49.2769\tvalid_1's rmse: 60.9808\n",
      "[15]\ttraining's rmse: 48.559\tvalid_1's rmse: 61.0884\n",
      "[16]\ttraining's rmse: 47.7809\tvalid_1's rmse: 60.6058\n",
      "[17]\ttraining's rmse: 47.0865\tvalid_1's rmse: 60.6392\n",
      "[18]\ttraining's rmse: 46.4853\tvalid_1's rmse: 60.8109\n",
      "[19]\ttraining's rmse: 45.9245\tvalid_1's rmse: 60.5192\n",
      "[20]\ttraining's rmse: 45.3811\tvalid_1's rmse: 60.2771\n",
      "[21]\ttraining's rmse: 44.8651\tvalid_1's rmse: 60.5995\n",
      "[22]\ttraining's rmse: 44.2652\tvalid_1's rmse: 60.4759\n",
      "[23]\ttraining's rmse: 43.7\tvalid_1's rmse: 60.3562\n",
      "[24]\ttraining's rmse: 43.2219\tvalid_1's rmse: 60.2862\n",
      "[25]\ttraining's rmse: 42.7979\tvalid_1's rmse: 60.6623\n",
      "[26]\ttraining's rmse: 42.317\tvalid_1's rmse: 60.7439\n",
      "[27]\ttraining's rmse: 41.9923\tvalid_1's rmse: 60.8512\n",
      "[28]\ttraining's rmse: 41.6334\tvalid_1's rmse: 60.7294\n",
      "[29]\ttraining's rmse: 41.3099\tvalid_1's rmse: 60.6404\n",
      "[30]\ttraining's rmse: 40.8855\tvalid_1's rmse: 60.3752\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's rmse: 45.3811\tvalid_1's rmse: 60.2771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "     params=params,\n",
    "     train_set=dtrain,\n",
    "     valid_sets=[dtrain, dvalid],\n",
    "     num_boost_round=10000,\n",
    "     early_stopping_rounds=10,\n",
    "     verbose_eval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a36eab31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.733714122137485"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test[target], model.predict(test[features]))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b1f728",
   "metadata": {},
   "source": [
    "# Custom Objectiveを使って再現する\n",
    "- Reference\n",
    "    - https://www.f-denshi.com/000TokiwaJPN/10kaisk/040ksk.html\n",
    "    - https://speakerdeck.com/rsakata/santander-product-recommendationfalseapurotitoxgboostfalsexiao-neta\n",
    "    - https://hippocampus-garden.com/lgbm_custom/\n",
    "    - https://yaakublog.com/lightgbm_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e680db",
   "metadata": {},
   "source": [
    "$L(y_{pred}+w, y) - L(y_{pred}, y)$を最小化するwを求める。　\n",
    "\n",
    "一般にテイラー展開より以下が成り立つ。\n",
    "$$\n",
    "    f(x+h) = f(x) + \\frac{f'(x)}{1!}h + \\frac{f''(x)}{2!}h^2 + ......\n",
    "$$\n",
    "よって二次近似まで使うとすると\n",
    "$$\n",
    "    \\Delta L = L(y_{pred}+w, y) - L(y_{pred}, y) \\approx L'(y_{pred}, y)w + \\frac{L''(y_{pred}, y)}{2}w^2\n",
    "$$\n",
    "この$\\Delta L$の和を最小化するwを求める\n",
    "$$\n",
    "    f(w) = \\sum_i^n (L'(y_{pred, i}, y_i)w + \\frac{L''(y_{pred, i}, y_i)}{2}w^2), \\quad \\\\\n",
    "    \\frac{df(w)}{dw} = \\sum_i^n (L'(y_{pred, i}, y_i) + L''(y_{pred, i}, y_i)w) = 0, \\quad \\\\\n",
    "    w = - \\frac{\\sum_i^n L'(y_{pred, i}, y_i)}{\\sum_i^n L''(y_{pred, i}, y_i)} \\\\\n",
    "    (結果1階微分/2階微分になりニュートン法に近くなる)\n",
    "$$\n",
    "ここで例えば$L(y_{pred}, y) = \\frac{1}{2}(y_{pred}- y)^2$とすると \n",
    "$$\n",
    "    L'(y_{pred}, y) = \\frac{dL(y_{pred}, y)}{dy_{pred}} =  y_{pred}- y, \\quad \\\\\n",
    "    L''(y_{pred}, y) = \\frac{d^2L(y_{pred}, y)}{dy_{pred}^2} = 1 \\quad \\\\\n",
    "    (おそらくyは正解ラベルなので定数として扱っていい。本当はL(y_{pred})と表記した方がわかりやすいかも)\n",
    "$$\n",
    "以上より$L(y_{pred}, y)$についての1階微分と2階微分が分かれば損失を最小化するwがわかる。(本当はもう少し正則化項とかが入る)\n",
    "\n",
    "GBDTではこのwを使って木を分岐した時に分岐しない時よりも損失が小さくなっていれば分岐を行うということを繰り返しモデルを構築する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3493f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, data):\n",
    "    label = data.get_label()\n",
    "    grad = pred - label\n",
    "    hess = np.ones_like(pred)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_init_score(y):\n",
    "    y = y.mean()\n",
    "    return np.log(y/(1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3f48b82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 151.635\tvalid_1's rmse: 170.931\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 138.427\tvalid_1's rmse: 157.107\n",
      "[3]\ttraining's rmse: 126.494\tvalid_1's rmse: 144.314\n",
      "[4]\ttraining's rmse: 115.994\tvalid_1's rmse: 133.34\n",
      "[5]\ttraining's rmse: 106.61\tvalid_1's rmse: 123.794\n",
      "[6]\ttraining's rmse: 98.3325\tvalid_1's rmse: 114.899\n",
      "[7]\ttraining's rmse: 91.1001\tvalid_1's rmse: 107.477\n",
      "[8]\ttraining's rmse: 84.6693\tvalid_1's rmse: 100.941\n",
      "[9]\ttraining's rmse: 79.0354\tvalid_1's rmse: 94.6975\n",
      "[10]\ttraining's rmse: 74.0264\tvalid_1's rmse: 89.4102\n",
      "[11]\ttraining's rmse: 69.6465\tvalid_1's rmse: 85.2989\n",
      "[12]\ttraining's rmse: 65.8493\tvalid_1's rmse: 81.7802\n",
      "[13]\ttraining's rmse: 62.5694\tvalid_1's rmse: 78.6893\n",
      "[14]\ttraining's rmse: 59.7069\tvalid_1's rmse: 75.868\n",
      "[15]\ttraining's rmse: 57.2599\tvalid_1's rmse: 73.7559\n",
      "[16]\ttraining's rmse: 55.0345\tvalid_1's rmse: 71.4946\n",
      "[17]\ttraining's rmse: 53.1152\tvalid_1's rmse: 69.9392\n",
      "[18]\ttraining's rmse: 51.48\tvalid_1's rmse: 68.7746\n",
      "[19]\ttraining's rmse: 50.054\tvalid_1's rmse: 67.3758\n",
      "[20]\ttraining's rmse: 48.7901\tvalid_1's rmse: 66.2032\n",
      "[21]\ttraining's rmse: 47.6751\tvalid_1's rmse: 65.6154\n",
      "[22]\ttraining's rmse: 46.5837\tvalid_1's rmse: 64.7531\n",
      "[23]\ttraining's rmse: 45.6103\tvalid_1's rmse: 64.0601\n",
      "[24]\ttraining's rmse: 44.792\tvalid_1's rmse: 63.4524\n",
      "[25]\ttraining's rmse: 44.0863\tvalid_1's rmse: 63.3973\n",
      "[26]\ttraining's rmse: 43.3751\tvalid_1's rmse: 63.1511\n",
      "[27]\ttraining's rmse: 42.8578\tvalid_1's rmse: 62.9491\n",
      "[28]\ttraining's rmse: 42.3418\tvalid_1's rmse: 62.5754\n",
      "[29]\ttraining's rmse: 41.8891\tvalid_1's rmse: 62.2484\n",
      "[30]\ttraining's rmse: 41.36\tvalid_1's rmse: 61.7796\n",
      "[31]\ttraining's rmse: 41.0156\tvalid_1's rmse: 61.591\n",
      "[32]\ttraining's rmse: 40.587\tvalid_1's rmse: 60.9905\n",
      "[33]\ttraining's rmse: 40.2194\tvalid_1's rmse: 60.7022\n",
      "[34]\ttraining's rmse: 39.8441\tvalid_1's rmse: 60.7565\n",
      "[35]\ttraining's rmse: 39.5258\tvalid_1's rmse: 60.6706\n",
      "[36]\ttraining's rmse: 39.2822\tvalid_1's rmse: 60.364\n",
      "[37]\ttraining's rmse: 38.9428\tvalid_1's rmse: 60.5439\n",
      "[38]\ttraining's rmse: 38.7266\tvalid_1's rmse: 60.3661\n",
      "[39]\ttraining's rmse: 38.4574\tvalid_1's rmse: 60.2526\n",
      "[40]\ttraining's rmse: 38.1579\tvalid_1's rmse: 59.8759\n",
      "[41]\ttraining's rmse: 37.9286\tvalid_1's rmse: 59.7164\n",
      "[42]\ttraining's rmse: 37.6827\tvalid_1's rmse: 59.3807\n",
      "[43]\ttraining's rmse: 37.3999\tvalid_1's rmse: 59.5413\n",
      "[44]\ttraining's rmse: 37.1715\tvalid_1's rmse: 59.5392\n",
      "[45]\ttraining's rmse: 36.9354\tvalid_1's rmse: 59.6004\n",
      "[46]\ttraining's rmse: 36.7404\tvalid_1's rmse: 59.6405\n",
      "[47]\ttraining's rmse: 36.5051\tvalid_1's rmse: 59.6944\n",
      "[48]\ttraining's rmse: 36.2775\tvalid_1's rmse: 59.8561\n",
      "[49]\ttraining's rmse: 36.1025\tvalid_1's rmse: 59.8922\n",
      "[50]\ttraining's rmse: 35.8679\tvalid_1's rmse: 59.8513\n",
      "[51]\ttraining's rmse: 35.6862\tvalid_1's rmse: 59.9053\n",
      "[52]\ttraining's rmse: 35.4685\tvalid_1's rmse: 60.0904\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 37.6827\tvalid_1's rmse: 59.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "     params=params,\n",
    "     train_set=dtrain,\n",
    "     valid_sets=[dtrain, dvalid],\n",
    "     fobj=mse_loss,\n",
    "     num_boost_round=10000,\n",
    "     early_stopping_rounds=10,\n",
    "     verbose_eval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "95901d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.27303609853879"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test[target], model.predict(test[features]))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c6385e",
   "metadata": {},
   "source": [
    "# 二値分類\n",
    "- https://yaakublog.com/lightgbm_custom\n",
    "- https://hippocampus-garden.com/lgbm_custom/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6871294",
   "metadata": {},
   "source": [
    "二値分類ではlogloss($L(y_{pred}, y) = -y\\log{y_{pred}}-(1-y)\\log{1 - y_{pred}}$)を使う ($y_{pred}=sigmoid(z) = \\frac{1}{1+e^{-z}}$とする)\n",
    "$$\n",
    "    L'(y_{pred}, y) = \\frac{dL(y_{pred}, y)}{dz} = \\frac{dL(y_{pred}, y)}{dy_{pred}}\\frac{dy_{pred}}{dz} =  - \\frac{y}{y_{pred}} + , \\frac{1-y}{1-y_{pred}} * y_{pred}(1-y_{pred}) = y_{pred} - y \\quad \\\\\n",
    "    L''(y_{pred}, y) = \\frac{d^2L(y_{pred}, y)}{dz^2} =  y_{pred}(1-y_{pred}) \\quad \\\\\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9e7266a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8e5288c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y = load_breast_cancer(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aa340f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "51d4f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'y'\n",
    "features = [c for c in df.columns if c != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "415e0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "train, valid = train_test_split(train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e66c0be9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((364, 31), (91, 31), (114, 31))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f9a04e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x142d0a520>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(data=train[features], label=train[target], free_raw_data=False)\n",
    "dtrain.construct()\n",
    "dvalid = lgb.Dataset(data=valid[features], label=valid[target], free_raw_data=False)\n",
    "dvalid.construct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fe76f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,\n",
    "    'metric': 'binary_logloss',\n",
    "    'nthread': -1,\n",
    "    'num_leaves': 7,\n",
    "    'seed': 57,\n",
    "    'verbose': -1,\n",
    "    \n",
    "#     'colsample_bytree': 0.05,\n",
    "#     'min_child_weight': 10,\n",
    "#     'min_split_gain': 0.1,\n",
    "#     'reg_alpha': 10,\n",
    "#     'reg_lambda': 1,\n",
    "#     'subsample': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c1d4e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.645604 -> initscore=0.599773\n",
      "[LightGBM] [Info] Start training from score 0.599773\n",
      "[1]\ttraining's binary_logloss: 0.573192\tvalid_1's binary_logloss: 0.596102\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's binary_logloss: 0.51182\tvalid_1's binary_logloss: 0.533378\n",
      "[3]\ttraining's binary_logloss: 0.460513\tvalid_1's binary_logloss: 0.482405\n",
      "[4]\ttraining's binary_logloss: 0.418485\tvalid_1's binary_logloss: 0.43906\n",
      "[5]\ttraining's binary_logloss: 0.381564\tvalid_1's binary_logloss: 0.406099\n",
      "[6]\ttraining's binary_logloss: 0.349432\tvalid_1's binary_logloss: 0.375233\n",
      "[7]\ttraining's binary_logloss: 0.321732\tvalid_1's binary_logloss: 0.348324\n",
      "[8]\ttraining's binary_logloss: 0.2964\tvalid_1's binary_logloss: 0.321774\n",
      "[9]\ttraining's binary_logloss: 0.273762\tvalid_1's binary_logloss: 0.295187\n",
      "[10]\ttraining's binary_logloss: 0.251061\tvalid_1's binary_logloss: 0.278781\n",
      "[11]\ttraining's binary_logloss: 0.232048\tvalid_1's binary_logloss: 0.262439\n",
      "[12]\ttraining's binary_logloss: 0.216023\tvalid_1's binary_logloss: 0.251967\n",
      "[13]\ttraining's binary_logloss: 0.201642\tvalid_1's binary_logloss: 0.240574\n",
      "[14]\ttraining's binary_logloss: 0.187574\tvalid_1's binary_logloss: 0.225469\n",
      "[15]\ttraining's binary_logloss: 0.175699\tvalid_1's binary_logloss: 0.216351\n",
      "[16]\ttraining's binary_logloss: 0.163898\tvalid_1's binary_logloss: 0.204656\n",
      "[17]\ttraining's binary_logloss: 0.153855\tvalid_1's binary_logloss: 0.194451\n",
      "[18]\ttraining's binary_logloss: 0.141279\tvalid_1's binary_logloss: 0.1848\n",
      "[19]\ttraining's binary_logloss: 0.131103\tvalid_1's binary_logloss: 0.175487\n",
      "[20]\ttraining's binary_logloss: 0.12237\tvalid_1's binary_logloss: 0.168731\n",
      "[21]\ttraining's binary_logloss: 0.114066\tvalid_1's binary_logloss: 0.161771\n",
      "[22]\ttraining's binary_logloss: 0.106132\tvalid_1's binary_logloss: 0.154236\n",
      "[23]\ttraining's binary_logloss: 0.0985457\tvalid_1's binary_logloss: 0.151307\n",
      "[24]\ttraining's binary_logloss: 0.091967\tvalid_1's binary_logloss: 0.146886\n",
      "[25]\ttraining's binary_logloss: 0.0854004\tvalid_1's binary_logloss: 0.143659\n",
      "[26]\ttraining's binary_logloss: 0.080023\tvalid_1's binary_logloss: 0.138222\n",
      "[27]\ttraining's binary_logloss: 0.0747477\tvalid_1's binary_logloss: 0.13528\n",
      "[28]\ttraining's binary_logloss: 0.0701149\tvalid_1's binary_logloss: 0.129864\n",
      "[29]\ttraining's binary_logloss: 0.0650207\tvalid_1's binary_logloss: 0.129291\n",
      "[30]\ttraining's binary_logloss: 0.0604752\tvalid_1's binary_logloss: 0.128816\n",
      "[31]\ttraining's binary_logloss: 0.0562096\tvalid_1's binary_logloss: 0.126719\n",
      "[32]\ttraining's binary_logloss: 0.0529152\tvalid_1's binary_logloss: 0.123689\n",
      "[33]\ttraining's binary_logloss: 0.0488132\tvalid_1's binary_logloss: 0.124511\n",
      "[34]\ttraining's binary_logloss: 0.045431\tvalid_1's binary_logloss: 0.125813\n",
      "[35]\ttraining's binary_logloss: 0.0423692\tvalid_1's binary_logloss: 0.123108\n",
      "[36]\ttraining's binary_logloss: 0.0395218\tvalid_1's binary_logloss: 0.122174\n",
      "[37]\ttraining's binary_logloss: 0.0370428\tvalid_1's binary_logloss: 0.123181\n",
      "[38]\ttraining's binary_logloss: 0.0347463\tvalid_1's binary_logloss: 0.121816\n",
      "[39]\ttraining's binary_logloss: 0.0324562\tvalid_1's binary_logloss: 0.121736\n",
      "[40]\ttraining's binary_logloss: 0.0304303\tvalid_1's binary_logloss: 0.120147\n",
      "[41]\ttraining's binary_logloss: 0.0284552\tvalid_1's binary_logloss: 0.120348\n",
      "[42]\ttraining's binary_logloss: 0.0262786\tvalid_1's binary_logloss: 0.122303\n",
      "[43]\ttraining's binary_logloss: 0.0245348\tvalid_1's binary_logloss: 0.121254\n",
      "[44]\ttraining's binary_logloss: 0.0230114\tvalid_1's binary_logloss: 0.122198\n",
      "[45]\ttraining's binary_logloss: 0.0212446\tvalid_1's binary_logloss: 0.122378\n",
      "[46]\ttraining's binary_logloss: 0.0198349\tvalid_1's binary_logloss: 0.122147\n",
      "[47]\ttraining's binary_logloss: 0.0185446\tvalid_1's binary_logloss: 0.124449\n",
      "[48]\ttraining's binary_logloss: 0.0173286\tvalid_1's binary_logloss: 0.126728\n",
      "[49]\ttraining's binary_logloss: 0.0162474\tvalid_1's binary_logloss: 0.127578\n",
      "[50]\ttraining's binary_logloss: 0.0153429\tvalid_1's binary_logloss: 0.12882\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.0304303\tvalid_1's binary_logloss: 0.120147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "     params=params,\n",
    "     train_set=dtrain,\n",
    "     valid_sets=[dtrain, dvalid],\n",
    "     num_boost_round=10000,\n",
    "     early_stopping_rounds=10,\n",
    "     verbose_eval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c61fc92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2624420125901359"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test[target], model.predict(test[features]))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eca93e",
   "metadata": {},
   "source": [
    "# Custom Objectiveを自作する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "633c4939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(y):\n",
    "    return 1 / (1+np.exp(-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f2594b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss_loss(z, data):\n",
    "    label = data.get_label()\n",
    "    pred = sigmoid(z)\n",
    "    grad = pred - label\n",
    "    hess = pred*(1-pred)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fd10cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss_eval(z, data):\n",
    "    label = data.get_label()\n",
    "    pred = sigmoid(z)\n",
    "    loss = -(label * np.log(pred) + (1-label)*np.log(1-pred))    \n",
    "    return 'custom_logloss', np.mean(loss), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9c1002d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['metric'] = 'custom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d4d55c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二値分類の場合、学習データの正例・負例の対数オッズ比で初期値が設定されている\n",
    "def original_init_score(y):\n",
    "    y = y.mean()\n",
    "    return np.log(y/(1-y))\n",
    "\n",
    "dtrain = lgb.Dataset(data=train[features], label=train[target], init_score=np.full_like(train[target], original_init_score(train[target]), dtype=float))\n",
    "dvalid = lgb.Dataset(data=valid[features], label=valid[target], init_score=np.full_like(valid[target], original_init_score(train[target]), dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bee51649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's custom_logloss: 0.573192\tvalid_1's custom_logloss: 0.596102\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's custom_logloss: 0.51182\tvalid_1's custom_logloss: 0.533378\n",
      "[3]\ttraining's custom_logloss: 0.460513\tvalid_1's custom_logloss: 0.482405\n",
      "[4]\ttraining's custom_logloss: 0.418485\tvalid_1's custom_logloss: 0.43906\n",
      "[5]\ttraining's custom_logloss: 0.381564\tvalid_1's custom_logloss: 0.406099\n",
      "[6]\ttraining's custom_logloss: 0.349432\tvalid_1's custom_logloss: 0.375233\n",
      "[7]\ttraining's custom_logloss: 0.321732\tvalid_1's custom_logloss: 0.348324\n",
      "[8]\ttraining's custom_logloss: 0.2964\tvalid_1's custom_logloss: 0.321774\n",
      "[9]\ttraining's custom_logloss: 0.273762\tvalid_1's custom_logloss: 0.295187\n",
      "[10]\ttraining's custom_logloss: 0.251061\tvalid_1's custom_logloss: 0.278781\n",
      "[11]\ttraining's custom_logloss: 0.232048\tvalid_1's custom_logloss: 0.262439\n",
      "[12]\ttraining's custom_logloss: 0.216023\tvalid_1's custom_logloss: 0.251967\n",
      "[13]\ttraining's custom_logloss: 0.201642\tvalid_1's custom_logloss: 0.240574\n",
      "[14]\ttraining's custom_logloss: 0.187574\tvalid_1's custom_logloss: 0.225469\n",
      "[15]\ttraining's custom_logloss: 0.175699\tvalid_1's custom_logloss: 0.216351\n",
      "[16]\ttraining's custom_logloss: 0.163898\tvalid_1's custom_logloss: 0.204656\n",
      "[17]\ttraining's custom_logloss: 0.153855\tvalid_1's custom_logloss: 0.194451\n",
      "[18]\ttraining's custom_logloss: 0.141279\tvalid_1's custom_logloss: 0.1848\n",
      "[19]\ttraining's custom_logloss: 0.131103\tvalid_1's custom_logloss: 0.175487\n",
      "[20]\ttraining's custom_logloss: 0.12237\tvalid_1's custom_logloss: 0.168731\n",
      "[21]\ttraining's custom_logloss: 0.114066\tvalid_1's custom_logloss: 0.161771\n",
      "[22]\ttraining's custom_logloss: 0.106132\tvalid_1's custom_logloss: 0.154236\n",
      "[23]\ttraining's custom_logloss: 0.0985457\tvalid_1's custom_logloss: 0.151307\n",
      "[24]\ttraining's custom_logloss: 0.091967\tvalid_1's custom_logloss: 0.146886\n",
      "[25]\ttraining's custom_logloss: 0.0854004\tvalid_1's custom_logloss: 0.143659\n",
      "[26]\ttraining's custom_logloss: 0.080023\tvalid_1's custom_logloss: 0.138222\n",
      "[27]\ttraining's custom_logloss: 0.0747477\tvalid_1's custom_logloss: 0.13528\n",
      "[28]\ttraining's custom_logloss: 0.0701149\tvalid_1's custom_logloss: 0.129864\n",
      "[29]\ttraining's custom_logloss: 0.0650207\tvalid_1's custom_logloss: 0.129291\n",
      "[30]\ttraining's custom_logloss: 0.0604752\tvalid_1's custom_logloss: 0.128816\n",
      "[31]\ttraining's custom_logloss: 0.0562096\tvalid_1's custom_logloss: 0.126719\n",
      "[32]\ttraining's custom_logloss: 0.0529152\tvalid_1's custom_logloss: 0.123689\n",
      "[33]\ttraining's custom_logloss: 0.0488132\tvalid_1's custom_logloss: 0.124511\n",
      "[34]\ttraining's custom_logloss: 0.045431\tvalid_1's custom_logloss: 0.125813\n",
      "[35]\ttraining's custom_logloss: 0.0423692\tvalid_1's custom_logloss: 0.123108\n",
      "[36]\ttraining's custom_logloss: 0.0395218\tvalid_1's custom_logloss: 0.122174\n",
      "[37]\ttraining's custom_logloss: 0.0370428\tvalid_1's custom_logloss: 0.123181\n",
      "[38]\ttraining's custom_logloss: 0.0347463\tvalid_1's custom_logloss: 0.121816\n",
      "[39]\ttraining's custom_logloss: 0.0324562\tvalid_1's custom_logloss: 0.121736\n",
      "[40]\ttraining's custom_logloss: 0.0304303\tvalid_1's custom_logloss: 0.120147\n",
      "[41]\ttraining's custom_logloss: 0.0284552\tvalid_1's custom_logloss: 0.120348\n",
      "[42]\ttraining's custom_logloss: 0.0262786\tvalid_1's custom_logloss: 0.122303\n",
      "[43]\ttraining's custom_logloss: 0.0245348\tvalid_1's custom_logloss: 0.121254\n",
      "[44]\ttraining's custom_logloss: 0.0230114\tvalid_1's custom_logloss: 0.122198\n",
      "[45]\ttraining's custom_logloss: 0.0212446\tvalid_1's custom_logloss: 0.122378\n",
      "[46]\ttraining's custom_logloss: 0.0198349\tvalid_1's custom_logloss: 0.122147\n",
      "[47]\ttraining's custom_logloss: 0.0185446\tvalid_1's custom_logloss: 0.124449\n",
      "[48]\ttraining's custom_logloss: 0.0173286\tvalid_1's custom_logloss: 0.126728\n",
      "[49]\ttraining's custom_logloss: 0.0162474\tvalid_1's custom_logloss: 0.127578\n",
      "[50]\ttraining's custom_logloss: 0.0153429\tvalid_1's custom_logloss: 0.12882\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's custom_logloss: 0.0304303\tvalid_1's custom_logloss: 0.120147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "     params=params,\n",
    "     train_set=dtrain,\n",
    "     valid_sets=[dtrain, dvalid],\n",
    "     fobj=logloss_loss,\n",
    "     feval=logloss_eval,\n",
    "     num_boost_round=10000,\n",
    "     early_stopping_rounds=10,\n",
    "     verbose_eval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "88faa92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27483791362430254"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(test[target], sigmoid(model.predict(test[features])))**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
