{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a3bdf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3835e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63457dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fab0547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbb57342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y = load_diabetes(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81c542d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfe13e",
   "metadata": {},
   "source": [
    "# まず連続値の予測\n",
    "- 糖尿病患者の検査数値と1年後の進行状況のデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c491d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'y'\n",
    "features = [c for c in df.columns if c != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4623d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "train, valid = train_test_split(train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b43ac21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x1327435b0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(data=train[features], label=train[target], free_raw_data=False)\n",
    "dtrain.construct()\n",
    "dvalid = lgb.Dataset(data=valid[features], label=valid[target], free_raw_data=False)\n",
    "dvalid.construct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "84d2c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,\n",
    "    'metric': 'root_mean_squared_error',\n",
    "    'nthread': -1,\n",
    "    'num_leaves': 7,\n",
    "    'seed': 57,\n",
    "    'verbose': -1,\n",
    "    \n",
    "#     'colsample_bytree': 0.05,\n",
    "#     'min_child_weight': 10,\n",
    "#     'min_split_gain': 0.1,\n",
    "#     'reg_alpha': 10,\n",
    "#     'reg_lambda': 1,\n",
    "#     'subsample': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "daad67bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 73.4856\tvalid_1's rmse: 78.4953\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 70.0847\tvalid_1's rmse: 75.6773\n",
      "[3]\ttraining's rmse: 66.7682\tvalid_1's rmse: 72.4375\n",
      "[4]\ttraining's rmse: 64.0703\tvalid_1's rmse: 70.2267\n",
      "[5]\ttraining's rmse: 61.5833\tvalid_1's rmse: 68.49\n",
      "[6]\ttraining's rmse: 59.4559\tvalid_1's rmse: 66.4946\n",
      "[7]\ttraining's rmse: 57.7101\tvalid_1's rmse: 65.2463\n",
      "[8]\ttraining's rmse: 56.0731\tvalid_1's rmse: 64.1842\n",
      "[9]\ttraining's rmse: 54.6497\tvalid_1's rmse: 62.9557\n",
      "[10]\ttraining's rmse: 53.2851\tvalid_1's rmse: 62.1439\n",
      "[11]\ttraining's rmse: 52.0745\tvalid_1's rmse: 61.7006\n",
      "[12]\ttraining's rmse: 51.0258\tvalid_1's rmse: 61.6334\n",
      "[13]\ttraining's rmse: 50.1159\tvalid_1's rmse: 61.426\n",
      "[14]\ttraining's rmse: 49.2769\tvalid_1's rmse: 60.9808\n",
      "[15]\ttraining's rmse: 48.559\tvalid_1's rmse: 61.0884\n",
      "[16]\ttraining's rmse: 47.7809\tvalid_1's rmse: 60.6058\n",
      "[17]\ttraining's rmse: 47.0865\tvalid_1's rmse: 60.6392\n",
      "[18]\ttraining's rmse: 46.4853\tvalid_1's rmse: 60.8109\n",
      "[19]\ttraining's rmse: 45.9245\tvalid_1's rmse: 60.5192\n",
      "[20]\ttraining's rmse: 45.3811\tvalid_1's rmse: 60.2771\n",
      "[21]\ttraining's rmse: 44.8651\tvalid_1's rmse: 60.5995\n",
      "[22]\ttraining's rmse: 44.2652\tvalid_1's rmse: 60.4759\n",
      "[23]\ttraining's rmse: 43.7\tvalid_1's rmse: 60.3562\n",
      "[24]\ttraining's rmse: 43.2219\tvalid_1's rmse: 60.2862\n",
      "[25]\ttraining's rmse: 42.7979\tvalid_1's rmse: 60.6623\n",
      "[26]\ttraining's rmse: 42.317\tvalid_1's rmse: 60.7439\n",
      "[27]\ttraining's rmse: 41.9923\tvalid_1's rmse: 60.8512\n",
      "[28]\ttraining's rmse: 41.6334\tvalid_1's rmse: 60.7294\n",
      "[29]\ttraining's rmse: 41.3099\tvalid_1's rmse: 60.6404\n",
      "[30]\ttraining's rmse: 40.8855\tvalid_1's rmse: 60.3752\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's rmse: 45.3811\tvalid_1's rmse: 60.2771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "     params=params,\n",
    "     train_set=dtrain,\n",
    "     valid_sets=[dtrain, dvalid],\n",
    "     num_boost_round=10000,\n",
    "     early_stopping_rounds=10,\n",
    "     verbose_eval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e51efe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.733714122137485"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test[target], model.predict(test[features]))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d0da4",
   "metadata": {},
   "source": [
    "# Custom Objectiveを使って再現する\n",
    "- Reference\n",
    "    - https://www.f-denshi.com/000TokiwaJPN/10kaisk/040ksk.html\n",
    "    - https://speakerdeck.com/rsakata/santander-product-recommendationfalseapurotitoxgboostfalsexiao-neta\n",
    "    - https://hippocampus-garden.com/lgbm_custom/\n",
    "    - https://yaakublog.com/lightgbm_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5318462",
   "metadata": {},
   "source": [
    "$L(y_{pred}+w, y) - L(y_{pred}, y)$を最小化するwを求める。　\n",
    "\n",
    "一般にテイラー展開より以下が成り立つ。\n",
    "$$\n",
    "    f(x+h) = f(x) + \\frac{f'(x)}{1!}h + \\frac{f''(x)}{2!}h^2 + ......\n",
    "$$\n",
    "よって二次近似まで使うとすると\n",
    "$$\n",
    "    \\Delta L = L(y_{pred}+w, y) - L(y_{pred}, y) \\approx L'(y_{pred}, y)w + \\frac{L''(y_{pred}, y)}{2}w^2\n",
    "$$\n",
    "この$\\Delta L$の和を最小化するwを求める\n",
    "$$\n",
    "    f(w) = \\sum_i^n (L'(y_{pred, i}, y_i)w + \\frac{L''(y_{pred, i}, y_i)}{2}w^2), \\quad \\\\\n",
    "    \\frac{df(w)}{dw} = \\sum_i^n (L'(y_{pred, i}, y_i) + L''(y_{pred, i}, y_i)w) = 0, \\quad \\\\\n",
    "    w = - \\frac{\\sum_i^n L'(y_{pred, i}, y_i)}{\\sum_i^n L''(y_{pred, i}, y_i)} \\\\\n",
    "    (結果1階微分/2階微分になりニュートン法に近くなる)\n",
    "$$\n",
    "ここで例えば$L(y_{pred}, y) = \\frac{1}{2}(y_{pred}- y)^2$とすると \n",
    "$$\n",
    "    L'(y_{pred}, y) = \\frac{dL(y_{pred}, y)}{dy_{pred}} =  y_{pred}- y, \\quad \\\\\n",
    "    L''(y_{pred}, y) = \\frac{d^2L(y_{pred}, y)}{dy_{pred}^2} = 1 \\quad \\\\\n",
    "    (おそらくyは正解ラベルなので定数として扱っていい。本当はL(y_{pred})と表記した方がわかりやすいかも)\n",
    "$$\n",
    "以上より$L(y_{pred}, y)$についての1階微分と2階微分が分かれば損失を最小化するwがわかる。(本当はもう少し正則化項とかが入る)\n",
    "\n",
    "GBDTではこのwを使って木を分岐した時に分岐しない時よりも損失が小さくなっていれば分岐を行うということを繰り返しモデルを構築する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28a5fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, data):\n",
    "    label = data.get_label()\n",
    "    grad = pred - label\n",
    "    hess = np.ones_like(pred)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bacc5fd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's rmse: 151.635\tvalid_1's rmse: 170.931\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's rmse: 138.427\tvalid_1's rmse: 157.107\n",
      "[3]\ttraining's rmse: 126.494\tvalid_1's rmse: 144.314\n",
      "[4]\ttraining's rmse: 115.994\tvalid_1's rmse: 133.34\n",
      "[5]\ttraining's rmse: 106.61\tvalid_1's rmse: 123.794\n",
      "[6]\ttraining's rmse: 98.3325\tvalid_1's rmse: 114.899\n",
      "[7]\ttraining's rmse: 91.1001\tvalid_1's rmse: 107.477\n",
      "[8]\ttraining's rmse: 84.6693\tvalid_1's rmse: 100.941\n",
      "[9]\ttraining's rmse: 79.0354\tvalid_1's rmse: 94.6975\n",
      "[10]\ttraining's rmse: 74.0264\tvalid_1's rmse: 89.4102\n",
      "[11]\ttraining's rmse: 69.6465\tvalid_1's rmse: 85.2989\n",
      "[12]\ttraining's rmse: 65.8493\tvalid_1's rmse: 81.7802\n",
      "[13]\ttraining's rmse: 62.5694\tvalid_1's rmse: 78.6893\n",
      "[14]\ttraining's rmse: 59.7069\tvalid_1's rmse: 75.868\n",
      "[15]\ttraining's rmse: 57.2599\tvalid_1's rmse: 73.7559\n",
      "[16]\ttraining's rmse: 55.0345\tvalid_1's rmse: 71.4946\n",
      "[17]\ttraining's rmse: 53.1152\tvalid_1's rmse: 69.9392\n",
      "[18]\ttraining's rmse: 51.48\tvalid_1's rmse: 68.7746\n",
      "[19]\ttraining's rmse: 50.054\tvalid_1's rmse: 67.3758\n",
      "[20]\ttraining's rmse: 48.7901\tvalid_1's rmse: 66.2032\n",
      "[21]\ttraining's rmse: 47.6751\tvalid_1's rmse: 65.6154\n",
      "[22]\ttraining's rmse: 46.5837\tvalid_1's rmse: 64.7531\n",
      "[23]\ttraining's rmse: 45.6103\tvalid_1's rmse: 64.0601\n",
      "[24]\ttraining's rmse: 44.792\tvalid_1's rmse: 63.4524\n",
      "[25]\ttraining's rmse: 44.0863\tvalid_1's rmse: 63.3973\n",
      "[26]\ttraining's rmse: 43.3751\tvalid_1's rmse: 63.1511\n",
      "[27]\ttraining's rmse: 42.8578\tvalid_1's rmse: 62.9491\n",
      "[28]\ttraining's rmse: 42.3418\tvalid_1's rmse: 62.5754\n",
      "[29]\ttraining's rmse: 41.8891\tvalid_1's rmse: 62.2484\n",
      "[30]\ttraining's rmse: 41.36\tvalid_1's rmse: 61.7796\n",
      "[31]\ttraining's rmse: 41.0156\tvalid_1's rmse: 61.591\n",
      "[32]\ttraining's rmse: 40.587\tvalid_1's rmse: 60.9905\n",
      "[33]\ttraining's rmse: 40.2194\tvalid_1's rmse: 60.7022\n",
      "[34]\ttraining's rmse: 39.8441\tvalid_1's rmse: 60.7565\n",
      "[35]\ttraining's rmse: 39.5258\tvalid_1's rmse: 60.6706\n",
      "[36]\ttraining's rmse: 39.2822\tvalid_1's rmse: 60.364\n",
      "[37]\ttraining's rmse: 38.9428\tvalid_1's rmse: 60.5439\n",
      "[38]\ttraining's rmse: 38.7266\tvalid_1's rmse: 60.3661\n",
      "[39]\ttraining's rmse: 38.4574\tvalid_1's rmse: 60.2526\n",
      "[40]\ttraining's rmse: 38.1579\tvalid_1's rmse: 59.8759\n",
      "[41]\ttraining's rmse: 37.9286\tvalid_1's rmse: 59.7164\n",
      "[42]\ttraining's rmse: 37.6827\tvalid_1's rmse: 59.3807\n",
      "[43]\ttraining's rmse: 37.3999\tvalid_1's rmse: 59.5413\n",
      "[44]\ttraining's rmse: 37.1715\tvalid_1's rmse: 59.5392\n",
      "[45]\ttraining's rmse: 36.9354\tvalid_1's rmse: 59.6004\n",
      "[46]\ttraining's rmse: 36.7404\tvalid_1's rmse: 59.6405\n",
      "[47]\ttraining's rmse: 36.5051\tvalid_1's rmse: 59.6944\n",
      "[48]\ttraining's rmse: 36.2775\tvalid_1's rmse: 59.8561\n",
      "[49]\ttraining's rmse: 36.1025\tvalid_1's rmse: 59.8922\n",
      "[50]\ttraining's rmse: 35.8679\tvalid_1's rmse: 59.8513\n",
      "[51]\ttraining's rmse: 35.6862\tvalid_1's rmse: 59.9053\n",
      "[52]\ttraining's rmse: 35.4685\tvalid_1's rmse: 60.0904\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 37.6827\tvalid_1's rmse: 59.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/Users/yagikei/Workspace/github.com/keeeeei79/scratch_optimization/.venv/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "     params=params,\n",
    "     train_set=dtrain,\n",
    "     valid_sets=[dtrain, dvalid],\n",
    "     fobj=mse_loss,\n",
    "     num_boost_round=10000,\n",
    "     early_stopping_rounds=10,\n",
    "     verbose_eval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "abc6e350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.27303609853879"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test[target], model.predict(test[features]))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627520d0",
   "metadata": {},
   "source": [
    "# 二値分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8318e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_init_score(y):\n",
    "    y = y.mean()\n",
    "    return np.log(y/(1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2869970",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(data=train[features], label=train[target], init_score=np.full_like(train[target], original_init_score(train[target]), dtype=float))\n",
    "dvalid = lgb.Dataset(data=valid[features], label=valid[target], init_score=np.full_like(valid[target], original_init_score(train[target]), dtype=float))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
